{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql.functions import mean\n",
    "from pyspark.ml.feature import VectorAssembler, ChiSqSelector\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import os\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LocalFeatureSelection\") \\\n",
    "    .config(\"spark.driver.memory\", \"55g\") \\\n",
    "    .config(\"spark.executor.memory\", \"55g\") \\\n",
    "    .config(\"spark.driver.cores\", \"8\") \\\n",
    "    .config(\"spark.executor.cores\", \"8\") \\\n",
    "    .master(\"local[8]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the split files\n",
    "directory = r\"C:\\Users\\hcymm3\\Desktop\\Dementia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through files split_1.csv to split_20.csv\n",
    "for i in range(1, 21):\n",
    "    # Construct the file path dynamically\n",
    "    file_path = os.path.join(directory, f\"split_{i}.csv\")\n",
    "\n",
    "    print(f\"Processing file: split_{i}.csv\")\n",
    "    # Read the CSV file into a Spark DataFrame\n",
    "    df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "    # Drop columns conditionally based on the index `i`\n",
    "    if i == 1:\n",
    "        # Drop the second column(SEX)\n",
    "        df = df.drop(df.columns[1])\n",
    "\n",
    "    # Get the schema of the DataFrame as a list of (column_name, data_type) tuples\n",
    "    schema = df.dtypes\n",
    "    # Identify all columns of type \"string\"\n",
    "    string_columns = [col_name for col_name, col_type in schema if col_type == \"string\"]\n",
    "    # Drop all string columns from the DataFrame\n",
    "    df = df.drop(*string_columns)\n",
    "\n",
    "    target_column = df.columns[0]\n",
    "    categorical_features = df.columns[1:]\n",
    "\n",
    "    \n",
    "    assembler = VectorAssembler(\n",
    "    inputCols=categorical_features,\n",
    "    outputCol='features'\n",
    ")\n",
    "\n",
    "    \n",
    "    assembled_df = assembler.transform(df)\n",
    "\n",
    "\n",
    "    selector = ChiSqSelector(\n",
    "    numTopFeatures=1000,  # Choose the top 1000 features (adjust as needed)\n",
    "    featuresCol='features',\n",
    "    outputCol='selectedFeatures',\n",
    "    labelCol=target_column\n",
    "    )\n",
    "\n",
    "\n",
    "    selected_model = selector.fit(assembled_df)\n",
    "    selected_data = selected_model.transform(assembled_df)\n",
    "\n",
    "\n",
    "    selected_indices = selected_model.selectedFeatures\n",
    "    selected_feature_names = [categorical_features[i] for i in selected_indices]\n",
    "\n",
    "    \n",
    "    final_columns = [target_column] + selected_feature_names\n",
    "    selected_df = df.select(*final_columns)\n",
    "\n",
    "    \n",
    "    rows = selected_df.collect()\n",
    "\n",
    "    columns = selected_df.columns\n",
    "    output_file = f'bestfeaturesChi_1.csv'\n",
    "# Write to a CSV file using the CSV module\n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(columns)  \n",
    "        writer.writerows(rows)    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
